# Karpenter Configuration to Auto-Scale NVIDIA GPU Nodes (G5/G4dn instances)
apiVersion: karpenter.sh/v1beta1
kind: NodePool
metadata:
  name: gpu-workers
spec:
  template:
    spec:
      requirements:
        - key: "karpenter.sh/capacity-type"
          operator: In
          values: ["on-demand", "spot"] # Use spot for cost-effective rendering
        - key: "node.kubernetes.io/instance-type"
          operator: In
          values: ["g4dn.xlarge", "g5.xlarge", "g5.2xlarge"] # NVIDIA T4 and A10G
        - key: "kubernetes.io/arch"
          operator: In
          values: ["amd64"]
      nodeClassRef:
        name: default
  limits:
    cpu: 1000
    memory: 1000Gi
    nvidia.com/gpu: 50 # Max 50 GPUs active at once
  disruption:
    consolidationPolicy: WhenUnderutilized
    expireAfter: 720h
---
apiVersion: karpenter.k8s.aws/v1beta1
kind: EC2NodeClass
metadata:
  name: default
spec:
  amiFamily: AL2 # Amazon Linux 2 (Optimized for EKS GPU)
  role: "KarpenterNodeRole-overlord-infra"
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: "overlord-infra"
  securityGroupSelectorTerms:
    - tags:
        kubernetes.io/cluster/overlord-infra: "owned"
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 100Gi # Large disk for caching AI models (SDXL weights)
        volumeType: gp3
        iops: 3000